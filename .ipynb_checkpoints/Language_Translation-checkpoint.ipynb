{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OdoeSEddN7IO"
   },
   "source": [
    "Language translation is a method of converting the source sentence from one natural language to another natural language using computerized systems and no human assistance is required. \n",
    "\n",
    "**Deep Learning** is a recently used approach for language translation. Unlike traditional machine translation, **neural machine** translation is a better choice for more accurate translation and also offers better performance. **Deep Neural Network** (`DNN`) can be used to improve traditional systems to make them more efficient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4mMi6EjuN7IU"
   },
   "source": [
    "Different **deep learning techniques and libraries** are needed to develop a better **language translation system**. `RNN`, `LSTM`, etc. are used to train the system which will convert the sentence from the source language to the target language.\n",
    "\n",
    "Adapting the appropriate networks and deep learning strategies is a good choice, as it has turned the system to maximize the accuracy of the translation system relative to others."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lq4bo27_N7IV"
   },
   "source": [
    "In this project, we will be creating a machine learning model to translate `English` to `Urdu`.\n",
    "\n",
    "Let’s get started with this task by importing the necessary Python libraries and the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "bog55eUJOIOF"
   },
   "outputs": [],
   "source": [
    "# IMPORT FILES FROM DRIVE INTO GOOGLE-COLAB:\n",
    "# Code to read csv file into colaboratory:\n",
    "# !pip install -U -q PyDrive\n",
    "\n",
    "# from pydrive.auth import GoogleAuth\n",
    "# from pydrive.drive import GoogleDrive\n",
    "# from google.colab import auth\n",
    "# from oauth2client.client import GoogleCredentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "ngz_OicEOTIC"
   },
   "outputs": [],
   "source": [
    "# Autheticate E-Mail ID\n",
    "\n",
    "# auth.authenticate_user()\n",
    "# gauth = GoogleAuth()\n",
    "# gauth.credentials = GoogleCredentials.get_application_default()\n",
    "# drive = GoogleDrive(gauth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "KFMiOjjcOoge"
   },
   "outputs": [],
   "source": [
    "# Get File from Drive using file-ID\n",
    "\n",
    "# downloaded = drive.CreateFile({'id':'1dWO-S5Bwk08U6e3rLSyoDDHFuT180vyk'}) # replace the id with id of file we want to access\n",
    "# downloaded.GetContentFile('Hindi_English_Truncated_Corpus.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "i1GShUb-N7IW"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "6XzsNrUGN7IW"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import string\n",
    "from string import digits\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Jyt7UmUlN7IX"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Vjd1EIuFN7IY"
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "9TpvGxB1N7IY"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Axsy8f7KN7IY"
   },
   "outputs": [],
   "source": [
    "lines=pd.read_csv(\"Hindi_English_Truncated_Corpus.csv\",encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "gQEQ8INxN7IZ"
   },
   "outputs": [],
   "source": [
    "lines=lines[lines['source']=='ted']\n",
    "lines=lines[~pd.isnull(lines['english_sentence'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Ya717vG0N7IZ"
   },
   "outputs": [],
   "source": [
    "lines.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rD62RDQVN7Ia",
    "outputId": "e1e8aad4-68b9-4e26-c1ae-d357802780dc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let us pick any 25000 rows from the dataset\n",
    "lines=lines.sample(n=25000,random_state=42)\n",
    "lines.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pHVh1jQcN7Ic"
   },
   "source": [
    "For simplicity, we will lowercase all the characters in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "x3SbNnCDN7Ic"
   },
   "outputs": [],
   "source": [
    "lines['english_sentence']=lines['english_sentence'].apply(lambda x: x.lower())\n",
    "lines['hindi_sentence']=lines['hindi_sentence'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7S3E12E8N7Ic"
   },
   "source": [
    "Now we will remove all the quotes from the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "TaCpaSUmN7Id"
   },
   "outputs": [],
   "source": [
    "lines['english_sentence']=lines['english_sentence'].apply(lambda x: re.sub(\"'\", '', x))\n",
    "lines['hindi_sentence']=lines['hindi_sentence'].apply(lambda x: re.sub(\"'\", '', x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rC9jKERnN7Id"
   },
   "source": [
    "Now we will remove all the special characters in the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "ZnHn4-kBN7Ie"
   },
   "outputs": [],
   "source": [
    "exclude = set(string.punctuation) # Set of all special characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "rRr8jdYkN7Ie"
   },
   "outputs": [],
   "source": [
    "# Remove all the special characters\n",
    "lines['english_sentence']=lines['english_sentence'].apply(lambda x: ''.join(ch for ch in x if ch not in exclude))\n",
    "lines['hindi_sentence']=lines['hindi_sentence'].apply(lambda x: ''.join(ch for ch in x if ch not in exclude))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AZ50UwKMN7Ie"
   },
   "source": [
    "Now we will remove all the numbers and extra spaces from the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "TGrXcze3N7If",
    "outputId": "be11c0b3-065c-413a-cd3a-99e5cc35eb17"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'0123456789'"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jatt8XZMN7If",
    "outputId": "d8100c35-d989-4b9b-ab13-0c08eb7d313c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{48: None,\n",
       " 49: None,\n",
       " 50: None,\n",
       " 51: None,\n",
       " 52: None,\n",
       " 53: None,\n",
       " 54: None,\n",
       " 55: None,\n",
       " 56: None,\n",
       " 57: None}"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_digits = str.maketrans('', '', digits)\n",
    "remove_digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "jLdO5NK8N7Ig"
   },
   "outputs": [],
   "source": [
    "lines['english_sentence']=lines['english_sentence'].apply(lambda x: x.translate(remove_digits))\n",
    "lines['hindi_sentence']=lines['hindi_sentence'].apply(lambda x: x.translate(remove_digits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "fBFfbv21N7Ig"
   },
   "outputs": [],
   "source": [
    "lines['hindi_sentence'] = lines['hindi_sentence'].apply(lambda x: re.sub(\"[२३०८१५७९४६]\", \"\", x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "ahrjrXYUN7Ig"
   },
   "outputs": [],
   "source": [
    "# Remove extra spaces\n",
    "lines['english_sentence']=lines['english_sentence'].apply(lambda x: x.strip())\n",
    "lines['hindi_sentence']=lines['hindi_sentence'].apply(lambda x: x.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "avWQCTRkN7Ih"
   },
   "outputs": [],
   "source": [
    "lines['english_sentence']=lines['english_sentence'].apply(lambda x: re.sub(\" +\", \" \", x))\n",
    "lines['hindi_sentence']=lines['hindi_sentence'].apply(lambda x: re.sub(\" +\", \" \", x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "FaQsT1eIN7Ij"
   },
   "outputs": [],
   "source": [
    "lines['hindi_sentence'] = lines['hindi_sentence'].apply(lambda x : 'START_ '+ x + ' _END')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B_qofNEUN7Ij",
    "outputId": "858006de-12f1-44f2-cd46-71ce140e8bdb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82040    START_ हम अभी तक नहीं जानते हैं कि उसके मातापि...\n",
       "85038                        START_ कोई कुंजीपटल नहीं _END\n",
       "58018              START_ लेकिन एक कलाकार होने के साथ _END\n",
       "Name: hindi_sentence, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines['hindi_sentence'].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XtW9k0OkN7Ik"
   },
   "source": [
    "Now we have cleared the dataset. The next thing we need to do is to prepare two sets of vocabularies of **Hindi** and **English**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "AFsJZZLqN7Ik"
   },
   "outputs": [],
   "source": [
    "# English Vocabulary\n",
    "\n",
    "all_eng_words=set()\n",
    "for eng in lines['english_sentence']:\n",
    "    for word in eng.split():\n",
    "        if word not in all_eng_words:\n",
    "            all_eng_words.add(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "4t4-CVL7N7Ik"
   },
   "outputs": [],
   "source": [
    "# Hindi Vocabulary\n",
    "\n",
    "all_hindi_words=set()\n",
    "for hin in lines['hindi_sentence']:\n",
    "    for word in hin.split():\n",
    "        if word not in all_hindi_words:\n",
    "            all_hindi_words.add(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "KapeW-_ZN7Il"
   },
   "outputs": [],
   "source": [
    "lines['length_eng_sentence']=lines['english_sentence'].apply(lambda x:len(x.split(\" \")))\n",
    "lines['length_hin_sentence']=lines['hindi_sentence'].apply(lambda x:len(x.split(\" \")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MZq7_pKtN7Il"
   },
   "source": [
    "Now before training the language translation model we need to set the **input** and **target** values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "q0HzLZ89N7Il"
   },
   "outputs": [],
   "source": [
    "lines=lines[lines['length_eng_sentence']<=20]\n",
    "lines=lines[lines['length_hin_sentence']<=20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "T0DxCskVN7Im"
   },
   "outputs": [],
   "source": [
    "max_length_src=max(lines['length_hin_sentence'])\n",
    "max_length_tar=max(lines['length_eng_sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "qzY80Y4VN7Im"
   },
   "outputs": [],
   "source": [
    "input_words = sorted(list(all_eng_words))\n",
    "target_words = sorted(list(all_hindi_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mNIxeG5WN7Im",
    "outputId": "d9af63d3-78ad-4f59-d04b-8bb5dc65b537"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14030 17540\n"
     ]
    }
   ],
   "source": [
    "num_encoder_tokens = len(all_eng_words)\n",
    "num_decoder_tokens = len(all_hindi_words)\n",
    "\n",
    "print(num_encoder_tokens, num_decoder_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rEenELajN7In",
    "outputId": "41e81cb9-8c73-4abb-cb58-0f07b83a3a71"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14031 17541\n"
     ]
    }
   ],
   "source": [
    "num_encoder_tokens += 1 # for zero padding\n",
    "num_decoder_tokens += 1 # for zero padding\n",
    "\n",
    "print(num_encoder_tokens, num_decoder_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "yV_d8R3NN7In"
   },
   "outputs": [],
   "source": [
    "input_token_index = dict([(word, i+1) for i, word in enumerate(input_words)])\n",
    "target_token_index = dict([(word, i+1) for i, word in enumerate(target_words)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "2a6cZomSN7Io"
   },
   "outputs": [],
   "source": [
    "reverse_input_char_index = dict((i, word) for word, i in input_token_index.items())\n",
    "reverse_target_char_index = dict((i, word) for word, i in target_token_index.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "PPJSGbGLN7Io"
   },
   "outputs": [],
   "source": [
    "lines = shuffle(lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lvJ3Xpv_N7Io"
   },
   "source": [
    "### Training Model to Translate English to Hindi\n",
    "\n",
    "Now as we have prepared our dataset let’s train a model for Language translation. For this task we will first split the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "4kv0NNfcN7Io"
   },
   "outputs": [],
   "source": [
    "X, y = lines['english_sentence'], lines['hindi_sentence']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2,\n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "7T7xGRJEN7Ip"
   },
   "outputs": [],
   "source": [
    "X_train.to_pickle('X_train.pkl')\n",
    "X_test.to_pickle('X_test.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9pbgs-9NN7Ip"
   },
   "source": [
    "Now let’s train our language translation model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "tDnSxs00N7Ip"
   },
   "outputs": [],
   "source": [
    "def generate_batch(X = X_train, y = y_train, batch_size = 128):\n",
    "    ''' Generate a batch of data '''\n",
    "    while True:\n",
    "        for j in range(0, len(X), batch_size):\n",
    "            encoder_input_data = np.zeros((batch_size, max_length_src),\n",
    "                                          dtype='float32')\n",
    "            decoder_input_data = np.zeros((batch_size, max_length_tar),\n",
    "                                          dtype='float32')\n",
    "            decoder_target_data = np.zeros((batch_size, max_length_tar,\n",
    "                                            num_decoder_tokens),dtype='float32')\n",
    "            for i, (input_text, target_text) in enumerate(zip(X[j:j+batch_size],\n",
    "                                                              y[j:j+batch_size])):\n",
    "                for t, word in enumerate(input_text.split()):\n",
    "                    encoder_input_data[i, t] = input_token_index[word] # encoder input seq\n",
    "                for t, word in enumerate(target_text.split()):\n",
    "                    if t<len(target_text.split())-1:\n",
    "                        decoder_input_data[i, t] = target_token_index[word] # decoder input seq\n",
    "                    if t>0:\n",
    "                        # decoder target sequence (one hot encoded)\n",
    "                        # does not include the START_ token\n",
    "                        # Offset by one timestep\n",
    "                        decoder_target_data[i, t - 1, target_token_index[word]] = 1.\n",
    "            yield([encoder_input_data, decoder_input_data], decoder_target_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "Jp6wFRSYN7Iq"
   },
   "outputs": [],
   "source": [
    "latent_dim=300\n",
    "encoder_inputs = Input(shape=(None,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "dG3xjcUqN7Iq"
   },
   "outputs": [],
   "source": [
    "enc_emb =  Embedding(num_encoder_tokens, latent_dim, \n",
    "                     mask_zero = True)(encoder_inputs)\n",
    "\n",
    "encoder_lstm = LSTM(latent_dim, return_state=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "iBd-JF2IN7Ir"
   },
   "outputs": [],
   "source": [
    "encoder_outputs, state_h, state_c = encoder_lstm(enc_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "Pj9q8KJEN7Is"
   },
   "outputs": [],
   "source": [
    "# We discard `encoder_outputs` and only keep the states.\n",
    "\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "-WJ5YYoyN7Is"
   },
   "outputs": [],
   "source": [
    "decoder_inputs = Input(shape=(None,))\n",
    "dec_emb_layer = Embedding(num_decoder_tokens, latent_dim, mask_zero = True)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "# We set up our decoder to return full output sequences,\n",
    "# and to return internal states as well. We don't use the\n",
    "# return states in the training model, but we will use them in inference.\n",
    "\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "AAH4tOMtN7It"
   },
   "outputs": [],
   "source": [
    "decoder_outputs, _, _ = decoder_lstm(dec_emb,initial_state=encoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "gXSNFmNyN7It"
   },
   "outputs": [],
   "source": [
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "__UUqzJiN7It",
    "outputId": "3ab15d84-11cd-4fa5-ebf0-d559b68c6aa7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, None, 300)    4209300     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 300)    5262300     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 300), (None, 721200      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, None, 300),  721200      embedding_1[0][0]                \n",
      "                                                                 lstm[0][1]                       \n",
      "                                                                 lstm[0][2]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 17541)  5279841     lstm_1[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 16,193,841\n",
      "Trainable params: 16,193,841\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model that will turn\n",
    "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "W1v2-uPpN7Iu"
   },
   "outputs": [],
   "source": [
    "train_samples = len(X_train)\n",
    "val_samples = len(X_test)\n",
    "batch_size = 128\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-c152TiDN7Iu",
    "outputId": "4907d3e8-4d31-40a7-d3b3-fb97668b998c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "154/154 [==============================] - 68s 202ms/step - loss: 3.2119 - val_loss: 2.8533\n",
      "Epoch 2/100\n",
      "154/154 [==============================] - 29s 186ms/step - loss: 2.7710 - val_loss: 2.6834\n",
      "Epoch 3/100\n",
      "154/154 [==============================] - 29s 188ms/step - loss: 2.5839 - val_loss: 2.6084\n",
      "Epoch 4/100\n",
      "154/154 [==============================] - 29s 186ms/step - loss: 2.4658 - val_loss: 2.5438\n",
      "Epoch 5/100\n",
      "154/154 [==============================] - 29s 186ms/step - loss: 2.3695 - val_loss: 2.5109\n",
      "Epoch 6/100\n",
      "154/154 [==============================] - 29s 187ms/step - loss: 2.2890 - val_loss: 2.4785\n",
      "Epoch 7/100\n",
      "154/154 [==============================] - 29s 186ms/step - loss: 2.2097 - val_loss: 2.4708\n",
      "Epoch 8/100\n",
      "154/154 [==============================] - 28s 184ms/step - loss: 2.1394 - val_loss: 2.4421\n",
      "Epoch 9/100\n",
      "154/154 [==============================] - 29s 186ms/step - loss: 2.0693 - val_loss: 2.4300\n",
      "Epoch 10/100\n",
      "154/154 [==============================] - 28s 184ms/step - loss: 2.0027 - val_loss: 2.4227\n",
      "Epoch 11/100\n",
      "154/154 [==============================] - 28s 185ms/step - loss: 1.9364 - val_loss: 2.4142\n",
      "Epoch 12/100\n",
      "154/154 [==============================] - 29s 188ms/step - loss: 1.8720 - val_loss: 2.4183\n",
      "Epoch 13/100\n",
      "154/154 [==============================] - 29s 187ms/step - loss: 1.8110 - val_loss: 2.4285\n",
      "Epoch 14/100\n",
      "154/154 [==============================] - 28s 185ms/step - loss: 1.7505 - val_loss: 2.4308\n",
      "Epoch 15/100\n",
      "154/154 [==============================] - 29s 187ms/step - loss: 1.6991 - val_loss: 2.4457\n",
      "Epoch 16/100\n",
      "154/154 [==============================] - 29s 188ms/step - loss: 1.6436 - val_loss: 2.4526\n",
      "Epoch 17/100\n",
      "154/154 [==============================] - 29s 186ms/step - loss: 1.5802 - val_loss: 2.4665\n",
      "Epoch 18/100\n",
      "154/154 [==============================] - 29s 186ms/step - loss: 1.5231 - val_loss: 2.4939\n",
      "Epoch 19/100\n",
      "154/154 [==============================] - 29s 186ms/step - loss: 1.4706 - val_loss: 2.5161\n",
      "Epoch 20/100\n",
      "154/154 [==============================] - 29s 187ms/step - loss: 1.4175 - val_loss: 2.5204\n",
      "Epoch 21/100\n",
      "154/154 [==============================] - 28s 185ms/step - loss: 1.3657 - val_loss: 2.5418\n",
      "Epoch 22/100\n",
      "154/154 [==============================] - 29s 185ms/step - loss: 1.3140 - val_loss: 2.5581\n",
      "Epoch 23/100\n",
      "154/154 [==============================] - 29s 188ms/step - loss: 1.2653 - val_loss: 2.5766\n",
      "Epoch 24/100\n",
      "154/154 [==============================] - 28s 184ms/step - loss: 1.2157 - val_loss: 2.6032\n",
      "Epoch 25/100\n",
      "154/154 [==============================] - 29s 188ms/step - loss: 1.1679 - val_loss: 2.6242\n",
      "Epoch 26/100\n",
      "154/154 [==============================] - 28s 185ms/step - loss: 1.1186 - val_loss: 2.6566\n",
      "Epoch 27/100\n",
      "154/154 [==============================] - 29s 187ms/step - loss: 1.0737 - val_loss: 2.6806\n",
      "Epoch 28/100\n",
      "154/154 [==============================] - 29s 188ms/step - loss: 1.0287 - val_loss: 2.6995\n",
      "Epoch 29/100\n",
      "154/154 [==============================] - 28s 185ms/step - loss: 0.9868 - val_loss: 2.7284\n",
      "Epoch 30/100\n",
      "154/154 [==============================] - 28s 184ms/step - loss: 0.9434 - val_loss: 2.7515\n",
      "Epoch 31/100\n",
      "154/154 [==============================] - 28s 185ms/step - loss: 0.9033 - val_loss: 2.7823\n",
      "Epoch 32/100\n",
      "154/154 [==============================] - 29s 186ms/step - loss: 0.8640 - val_loss: 2.7991\n",
      "Epoch 33/100\n",
      "154/154 [==============================] - 28s 183ms/step - loss: 0.8271 - val_loss: 2.8257\n",
      "Epoch 34/100\n",
      "154/154 [==============================] - 29s 188ms/step - loss: 0.7920 - val_loss: 2.8493\n",
      "Epoch 35/100\n",
      "154/154 [==============================] - 29s 187ms/step - loss: 0.7522 - val_loss: 2.8696\n",
      "Epoch 36/100\n",
      "154/154 [==============================] - 29s 185ms/step - loss: 0.7179 - val_loss: 2.8915\n",
      "Epoch 37/100\n",
      "154/154 [==============================] - 29s 186ms/step - loss: 0.6863 - val_loss: 2.9136\n",
      "Epoch 38/100\n",
      "154/154 [==============================] - 28s 185ms/step - loss: 0.6544 - val_loss: 2.9370\n",
      "Epoch 39/100\n",
      "154/154 [==============================] - 29s 186ms/step - loss: 0.6224 - val_loss: 2.9549\n",
      "Epoch 40/100\n",
      "154/154 [==============================] - 28s 185ms/step - loss: 0.5916 - val_loss: 2.9864\n",
      "Epoch 41/100\n",
      "154/154 [==============================] - 29s 186ms/step - loss: 0.5637 - val_loss: 2.9987\n",
      "Epoch 42/100\n",
      "154/154 [==============================] - 29s 189ms/step - loss: 0.5382 - val_loss: 3.0276\n",
      "Epoch 43/100\n",
      "154/154 [==============================] - 28s 185ms/step - loss: 0.5124 - val_loss: 3.0383\n",
      "Epoch 44/100\n",
      "154/154 [==============================] - 28s 185ms/step - loss: 0.4865 - val_loss: 3.0639\n",
      "Epoch 45/100\n",
      "154/154 [==============================] - 29s 186ms/step - loss: 0.4648 - val_loss: 3.0967\n",
      "Epoch 46/100\n",
      "154/154 [==============================] - 28s 185ms/step - loss: 0.4439 - val_loss: 3.1124\n",
      "Epoch 47/100\n",
      "154/154 [==============================] - 29s 187ms/step - loss: 0.4236 - val_loss: 3.1250\n",
      "Epoch 48/100\n",
      "154/154 [==============================] - 28s 185ms/step - loss: 0.4029 - val_loss: 3.1488\n",
      "Epoch 49/100\n",
      "154/154 [==============================] - 29s 186ms/step - loss: 0.3838 - val_loss: 3.1745\n",
      "Epoch 50/100\n",
      "154/154 [==============================] - 29s 187ms/step - loss: 0.3649 - val_loss: 3.1880\n",
      "Epoch 51/100\n",
      "154/154 [==============================] - 28s 183ms/step - loss: 0.3478 - val_loss: 3.2075\n",
      "Epoch 52/100\n",
      "154/154 [==============================] - 29s 187ms/step - loss: 0.3324 - val_loss: 3.2280\n",
      "Epoch 53/100\n",
      "154/154 [==============================] - 29s 186ms/step - loss: 0.3148 - val_loss: 3.2421\n",
      "Epoch 54/100\n",
      "154/154 [==============================] - 28s 185ms/step - loss: 0.2992 - val_loss: 3.2572\n",
      "Epoch 55/100\n",
      "154/154 [==============================] - 28s 185ms/step - loss: 0.2854 - val_loss: 3.2770\n",
      "Epoch 56/100\n",
      "154/154 [==============================] - 29s 186ms/step - loss: 0.2704 - val_loss: 3.2902\n",
      "Epoch 57/100\n",
      "154/154 [==============================] - 29s 186ms/step - loss: 0.2569 - val_loss: 3.3001\n",
      "Epoch 58/100\n",
      "154/154 [==============================] - 28s 184ms/step - loss: 0.2456 - val_loss: 3.3118\n",
      "Epoch 59/100\n",
      "154/154 [==============================] - 28s 185ms/step - loss: 0.2342 - val_loss: 3.3300\n",
      "Epoch 60/100\n",
      "154/154 [==============================] - 28s 185ms/step - loss: 0.2241 - val_loss: 3.3458\n",
      "Epoch 61/100\n",
      "154/154 [==============================] - 28s 182ms/step - loss: 0.2141 - val_loss: 3.3513\n",
      "Epoch 62/100\n",
      "154/154 [==============================] - 28s 183ms/step - loss: 0.2042 - val_loss: 3.3646\n",
      "Epoch 63/100\n",
      "154/154 [==============================] - 28s 184ms/step - loss: 0.1958 - val_loss: 3.3830\n",
      "Epoch 64/100\n",
      "154/154 [==============================] - 29s 186ms/step - loss: 0.1866 - val_loss: 3.3912\n",
      "Epoch 65/100\n",
      "154/154 [==============================] - 28s 183ms/step - loss: 0.1789 - val_loss: 3.4021\n",
      "Epoch 66/100\n",
      "154/154 [==============================] - 28s 185ms/step - loss: 0.1706 - val_loss: 3.4192\n",
      "Epoch 67/100\n",
      "154/154 [==============================] - 28s 183ms/step - loss: 0.1634 - val_loss: 3.4276\n",
      "Epoch 68/100\n",
      "154/154 [==============================] - 28s 184ms/step - loss: 0.1561 - val_loss: 3.4354\n",
      "Epoch 69/100\n",
      "154/154 [==============================] - 28s 185ms/step - loss: 0.1500 - val_loss: 3.4563\n",
      "Epoch 70/100\n",
      "154/154 [==============================] - 29s 185ms/step - loss: 0.1438 - val_loss: 3.4655\n",
      "Epoch 71/100\n",
      "154/154 [==============================] - 28s 184ms/step - loss: 0.1382 - val_loss: 3.4781\n",
      "Epoch 72/100\n",
      "154/154 [==============================] - 28s 184ms/step - loss: 0.1322 - val_loss: 3.4819\n",
      "Epoch 73/100\n",
      "154/154 [==============================] - 28s 184ms/step - loss: 0.1256 - val_loss: 3.4916\n",
      "Epoch 74/100\n",
      "154/154 [==============================] - 29s 186ms/step - loss: 0.1194 - val_loss: 3.5048\n",
      "Epoch 75/100\n",
      "154/154 [==============================] - 28s 185ms/step - loss: 0.1142 - val_loss: 3.5129\n",
      "Epoch 76/100\n",
      "154/154 [==============================] - 28s 185ms/step - loss: 0.1105 - val_loss: 3.5140\n",
      "Epoch 77/100\n",
      "154/154 [==============================] - 29s 185ms/step - loss: 0.1050 - val_loss: 3.5340\n",
      "Epoch 78/100\n",
      "154/154 [==============================] - 29s 186ms/step - loss: 0.1019 - val_loss: 3.5356\n",
      "Epoch 79/100\n",
      "154/154 [==============================] - 28s 184ms/step - loss: 0.0974 - val_loss: 3.5475\n",
      "Epoch 80/100\n",
      "154/154 [==============================] - 29s 186ms/step - loss: 0.0927 - val_loss: 3.5625\n",
      "Epoch 81/100\n",
      "154/154 [==============================] - 29s 186ms/step - loss: 0.0876 - val_loss: 3.5676\n",
      "Epoch 82/100\n",
      "154/154 [==============================] - 28s 184ms/step - loss: 0.0839 - val_loss: 3.5737\n",
      "Epoch 83/100\n",
      "154/154 [==============================] - 29s 186ms/step - loss: 0.0809 - val_loss: 3.5807\n",
      "Epoch 84/100\n",
      "154/154 [==============================] - 29s 185ms/step - loss: 0.0783 - val_loss: 3.5864\n",
      "Epoch 85/100\n",
      "154/154 [==============================] - 28s 184ms/step - loss: 0.0738 - val_loss: 3.5974\n",
      "Epoch 86/100\n",
      "154/154 [==============================] - 28s 185ms/step - loss: 0.0708 - val_loss: 3.6098\n",
      "Epoch 87/100\n",
      "154/154 [==============================] - 29s 187ms/step - loss: 0.0669 - val_loss: 3.6101\n",
      "Epoch 88/100\n",
      "154/154 [==============================] - 29s 186ms/step - loss: 0.0648 - val_loss: 3.6194\n",
      "Epoch 89/100\n",
      "154/154 [==============================] - 28s 183ms/step - loss: 0.0622 - val_loss: 3.6226\n",
      "Epoch 90/100\n",
      "154/154 [==============================] - 28s 184ms/step - loss: 0.0598 - val_loss: 3.6297\n",
      "Epoch 91/100\n",
      "154/154 [==============================] - 28s 185ms/step - loss: 0.0579 - val_loss: 3.6362\n",
      "Epoch 92/100\n",
      "154/154 [==============================] - 28s 184ms/step - loss: 0.0545 - val_loss: 3.6500\n",
      "Epoch 93/100\n",
      "154/154 [==============================] - 28s 185ms/step - loss: 0.0526 - val_loss: 3.6552\n",
      "Epoch 94/100\n",
      "154/154 [==============================] - 28s 183ms/step - loss: 0.0502 - val_loss: 3.6607\n",
      "Epoch 95/100\n",
      "154/154 [==============================] - 28s 184ms/step - loss: 0.0480 - val_loss: 3.6715\n",
      "Epoch 96/100\n",
      "154/154 [==============================] - 29s 186ms/step - loss: 0.0468 - val_loss: 3.6739\n",
      "Epoch 97/100\n",
      "154/154 [==============================] - 29s 185ms/step - loss: 0.0430 - val_loss: 3.6895\n",
      "Epoch 98/100\n",
      "154/154 [==============================] - 28s 184ms/step - loss: 0.0424 - val_loss: 3.6947\n",
      "Epoch 99/100\n",
      "154/154 [==============================] - 28s 184ms/step - loss: 0.0404 - val_loss: 3.7056\n",
      "Epoch 100/100\n",
      "154/154 [==============================] - 28s 185ms/step - loss: 0.0384 - val_loss: 3.7138\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f684b9a5d50>"
      ]
     },
     "execution_count": 48,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(generator = generate_batch(X_train, y_train, batch_size = batch_size),\n",
    "                    steps_per_epoch = train_samples//batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_data = generate_batch(X_test, y_test, batch_size = batch_size),\n",
    "                    validation_steps = val_samples//batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "dihwWNMXN7Iv"
   },
   "outputs": [],
   "source": [
    "model.save_weights('nmt_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "f7Z-QWDbazyK"
   },
   "outputs": [],
   "source": [
    "# Encode the input sequence to get the \"thought vectors\"\n",
    "encoder_model = Model(encoder_inputs, encoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "zyQsmJ5KN7Iw"
   },
   "outputs": [],
   "source": [
    "# Decoder setup\n",
    "# Below tensors will hold the states of the previous time step\n",
    "\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "ZSnTD4cwN7Ix"
   },
   "outputs": [],
   "source": [
    "dec_emb2= dec_emb_layer(decoder_inputs) # Get the embeddings of the decoder sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "CmXMvA8sa_Wr"
   },
   "outputs": [],
   "source": [
    "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=decoder_states_inputs)\n",
    "decoder_states2 = [state_h2, state_c2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "pMezwoWlbHEF"
   },
   "outputs": [],
   "source": [
    "decoder_outputs2 = decoder_dense(decoder_outputs2) # A dense softmax layer to generate prob dist. over the target vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "9Me7r_VXN7Ix"
   },
   "outputs": [],
   "source": [
    "# Final decoder model\n",
    "decoder_model = Model([decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs2] + decoder_states2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "y1vKGy-BN7Iy"
   },
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1,1))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0] = target_token_index['START_']\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += ' '+sampled_char\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (sampled_char == '_END' or\n",
    "           len(decoded_sentence) > 50):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "AS8LHkx7N7Iz"
   },
   "outputs": [],
   "source": [
    "train_gen = generate_batch(X_train, y_train, batch_size = 1)\n",
    "k=-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uRCg6UxpN7Iz"
   },
   "source": [
    "We have successfully built and trained our model for language translation. Now let’s see how the model performs by translating a sentence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "oLO7ciJVN7Iz"
   },
   "outputs": [],
   "source": [
    "k+=1\n",
    "\n",
    "(input_seq, actual_output), _ = next(train_gen)\n",
    "decoded_sentence = decode_sequence(input_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sTzPGwe4N7I0",
    "outputId": "58caf2f3-b66e-48b3-fe52-9b48b473f5cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input English sentence: from threat to pleasure\n",
      "Actual Hindi Translation:  खतरे से आनंद की ओर। \n",
      "Predicted Hindi Translation:  खतरे से आनंद की ओर। \n"
     ]
    }
   ],
   "source": [
    "print('Input English sentence:', X_train[k:k+1].values[0])\n",
    "print('Actual Hindi Translation:', y_train[k:k+1].values[0][6:-4])\n",
    "print('Predicted Hindi Translation:', decoded_sentence[:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NC-0d-FUN7I0"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Language Translation.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
